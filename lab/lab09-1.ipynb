{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모두를 위한 딥러닝 Lab#09-1\n",
    "#### 2018.07.04\n",
    "\n",
    "---\n",
    "\n",
    "- NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8158082 [[-0.40984195]\n",
      " [ 0.3776373 ]]\n",
      "1000 0.6931505 [[-0.00783646]\n",
      " [-0.00630442]]\n",
      "2000 0.6931472 [[-0.00014021]\n",
      " [-0.00013731]]\n",
      "3000 0.6931472 [[-2.700251e-06]\n",
      " [-2.698721e-06]]\n",
      "4000 0.6931472 [[-1.3276858e-07]\n",
      " [-1.3272879e-07]]\n",
      "5000 0.6931472 [[-1.3276858e-07]\n",
      " [-1.3272879e-07]]\n",
      "6000 0.6931472 [[-1.3276858e-07]\n",
      " [-1.3272879e-07]]\n",
      "7000 0.6931472 [[-1.3276858e-07]\n",
      " [-1.3272879e-07]]\n",
      "8000 0.6931472 [[-1.3276858e-07]\n",
      " [-1.3272879e-07]]\n",
      "9000 0.6931472 [[-1.3276858e-07]\n",
      " [-1.3272879e-07]]\n",
      "10000 0.6931472 [[-1.3276858e-07]\n",
      " [-1.3272879e-07]]\n",
      "hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]  correcy :  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]  accuracy :  0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0,0], [0,1], [1,0],[1,1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1],[0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10001) :\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if i % 1000 == 0:\n",
    "            print(i, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "            \n",
    "            \n",
    "    h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"hypothesis: \", h , \" correcy : \", c, \" accuracy : \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7070039 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "1000 0.61371917 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "2000 0.51728547 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "3000 0.23505251 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "4000 0.08411959 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "5000 0.047427893 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "6000 0.03249759 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "7000 0.024563698 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "8000 0.019682063 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "9000 0.016389364 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "10000 0.014024422 [[-0.13618447]\n",
      " [-0.17733528]]\n",
      "hypothesis:  [[0.01351883]\n",
      " [0.9881136 ]\n",
      " [0.9812242 ]\n",
      " [0.011508  ]]  correcy :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]  accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0,0], [0,1], [1,0],[1,1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1],[0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2,2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2,1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10001) :\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if i % 1000 == 0:\n",
    "            print(i, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "            \n",
    "            \n",
    "    h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"hypothesis: \", h , \" correcy : \", c, \" accuracy : \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wide NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9628123 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "1000 0.44891492 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "2000 0.12542781 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "3000 0.053347185 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "4000 0.031146917 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "5000 0.02128176 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "6000 0.015896667 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "7000 0.012563974 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "8000 0.010321664 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "9000 0.008720786 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "10000 0.0075262003 [[-0.81862724]\n",
      " [-1.49056   ]]\n",
      "hypothesis:  [[0.00674749]\n",
      " [0.99106747]\n",
      " [0.9935197 ]\n",
      " [0.00782961]]  correcy :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]  accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0,0], [0,1], [1,0],[1,1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1],[0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2,10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10,1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10001) :\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if i % 1000 == 0:\n",
    "            print(i, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "            \n",
    "            \n",
    "    h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"hypothesis: \", h , \" correcy : \", c, \" accuracy : \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7297658 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "1000 0.5828157 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "2000 0.031210134 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "3000 0.008068139 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "4000 0.0042533646 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "5000 0.0028124163 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "6000 0.0020750081 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "7000 0.0016326064 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "8000 0.0013398163 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "9000 0.0011326732 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "10000 0.0009788858 [[ 0.88566667]\n",
      " [-0.9451969 ]]\n",
      "hypothesis:  [[6.4006256e-04]\n",
      " [9.9885654e-01]\n",
      " [9.9909997e-01]\n",
      " [1.2299815e-03]]  correcy :  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]  accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0,0], [0,1], [1,0],[1,1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1],[0]], dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2,10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10,10]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([10,10]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([10]), name='bias3')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([10,1]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([1]), name='bias4')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
    "\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10001) :\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if i % 1000 == 0:\n",
    "            print(i, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))\n",
    "            \n",
    "            \n",
    "    h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"hypothesis: \", h , \" correcy : \", c, \" accuracy : \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
