{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모두를 위한 딥러닝 Lec#05-1\n",
    "#### 2018.06.11\n",
    "\n",
    "---\n",
    "\n",
    "- Logistic(Regression) classification\n",
    "\n",
    "- Binary Classification\n",
    "\n",
    "    > 두 개중 하나의 결과로 고른다\n",
    "\n",
    "    - 스팸 감지 : Spam(1) or Ham(0)\n",
    "    - 페이스북 피드 보여줄 지 말지 : show(1) or hide(0)\n",
    "    - 신용카드 사기성 거래 감지\n",
    "    - Radiology\n",
    "    - 주식\n",
    "    \n",
    "- Pass(1)/Fail(0) based on study hours\n",
    "\n",
    "    - Linear Regression를 그리고 0.5를 기준으로 0과 1로 나눈다..?\n",
    "    - 인풋이 매우 큰 값을 Linear Regression을 통해 학습시키면, 기준이 0.5보다 커져 잘못 학습되는 데이터들이 생길 수 있다.\n",
    "    > 결과가 -무한대에서 무한대까지 가질 수 있는 $ H(x) = Wx+b $ 형태의 함수가 아니라 0 부터 1의 결과를 갖는 함수를 찾게 됨. \n",
    "\n",
    "- **Sigmoid(Logistic) Function**\n",
    "$$ g(z) = \\frac{1}{(1+e^-z)} $$\n",
    "        \n",
    "- Logistic Hypothesis\n",
    "$$ H(X) = \\frac{1}{(1+e^-W^TX)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
